# Introduction {#sec-intro .unnumbered}

```{r}
#| echo: false

source("_common.R")
```

La science des donn√©es est une discipline passionnante qui permet de transformer des donn√©es brutes pour leur donner du sens et ouvrir des perspectives.
L'objectif de "R pour la science des donn√©es" est de vous aider √† apprendre les outils les plus importants en R qui vous permettront de faire de la science des donn√©es de mani√®re efficace et reproductible, tout en vous amusant üòÉ.
Apr√®s avoir lu ce livre, vous disposerez des outils n√©cessaires pour relever une grande vari√©t√© de d√©fis en science des donn√©es en utilisant les meilleures parties de R.

## Ce que vous allez apprendre

La science des donn√©es est un vaste domaine, et il n'est pas possible de le ma√Ætriser enti√®rement en lisant un seul livre.
Cet ouvrage vise √† vous donner une base solide en pr√©sentant les principaux outils et suffisamment de connaissances pour trouver les ressources n√©cessaires pour approfondir davantage lorsque cela est n√©cessaire.
Nous pensons un projet typique en science des donn√©es selon le mod√®le pr√©sent√© en @fig-ds-diagram.

```{r}
#| label: fig-ds-diagram
#| echo: false
#| fig-cap: |
#|   In our model of the data science process, you start with data import
#|   and tidying. Next, you understand your data with an iterative cycle of
#|   transforming, visualizing, and modeling. You finish the process 
#|   by communicating your results to other humans.
#| fig-alt: |
#|   A diagram displaying the data science cycle: Import -> Tidy -> Understand 
#|   (which has the phases Transform -> Visualize -> Model in a cycle) -> 
#|   Communicate. Surrounding all of these is Program.
#| out.width: NULL

knitr::include_graphics("diagrams/data-science/base.png", dpi = 270)
```

Tout d'abord, vous devez **importer** vos donn√©es dans R.
Cela signifie g√©n√©ralement que vous prenez des donn√©es stock√©es dans un fichier, une base de donn√©es existantes ou une interface de programmation d'application web (API pour web application programming interface) et que vous les chargez dans un tableau de donn√©es, ou *data frame*, dans R.
Si vous ne pouvez pas importer vos donn√©es dans R, vous ne pouvez pas faire de science des donn√©es !

Une fois que vous avez import√© vos donn√©es, il est bon de les ranger afin qu'elles soient **tidy** pour ordonn√©e en anglais.
On retrouvera ce terme fr√©quemment dans R car il donne son nom √† un ensemble de packages et plus largement √† une mani√®re de programmer.
Ranger vos donn√©es signifie les stocker sous une forme coh√©rente qui correspond √† la s√©mantique du jeu de donn√©es et √† la mani√®re dont elles sont stock√©es.
En bref, lorsque vos donn√©es sont rang√©es, chaque colonne est une variable et chaque ligne est une observation.
Avoir des donn√©es correctement rang√©es est important car une structure coh√©rente vous permet de concentrer vos efforts sur la r√©ponse aux questions concernant les donn√©es, plut√¥t que de lutter pour mettre les donn√©es dans la bonne forme pour diff√©rentes applications.

Une fois que vous avez des donn√©es rang√©es, une √©tape courante suivante est de les **transformer**.
La transformation inclut la d√©limitation d'un champ d'int√©r√™t (comme toutes les personnes dans une ville ou toutes les donn√©es de l'ann√©e derni√®re), la cr√©ation de nouvelles variables qui sont des indicateurs issus de variables existantes (comme le calcul de la vitesse √† partir de la distance et du temps), et le calcul d'un ensemble de statistiques descriptives (comme les d√©comptes ou les moyennes).
Ensemble, le rangement et la transformation sont appel√©s *wrangling*.

Une fois que vous avez des donn√©es rang√©es avec les variables dont vous avez besoin, il y a deux mani√®res de produire de la connaissance : la visualisation et la mod√©lisation.
Ces outils ont des forces et des faiblesses compl√©mentaires, donc toute bonne analyse de donn√©es alternera entre eux √† de multiples reprises.

::: callout-note
TODO
:::

La **visualisation** est une approche fondamentalement humaine.
Une bonne visualisation vous montrera des choses que vous ne vous attendiez pas √† voir ou soul√®vera de nouvelles questions sur les donn√©es.
Une bonne visualisation pourrait √©galement sugg√©rer que vous posez la mauvaise question ou que vous devez collecter des donn√©es diff√©rentes.
Les visualisations peuvent vous surprendre, mais elles peuvent induire en erreur car elles n√©cessitent une interpr√©tation humaine.

La **mod√©lisation** est une approche compl√©mentaires √† la visualisation.
Une fois que vous avez rendu vos questions suffisamment pr√©cises, vous pouvez utiliser un mod√®le pour y r√©pondre.
Les mod√®les sont fondamentalement des outils math√©matiques ou informatiques, donc ils se mettent g√©n√©ralement bien √† l'√©chelle.
M√™me lorsqu'ils ne le font pas, il est g√©n√©ralement moins co√ªteux d'acheter plus d'ordinateurs que d'acheter plus de cerveaux !
Mais chaque mod√®le fait des hypoth√®ses, et par nature, un mod√®le ne peut pas remettre en question ses propres hypoth√®ses.
Cela signifie qu'un mod√®le ne peut pas fondamentalement vous surprendre.

**Visualization** is a fundamentally human activity.
A good visualization will show you things you did not expect or raise new questions about the data.
A good visualization might also hint that you're asking the wrong question or that you need to collect different data.
Visualizations can surprise you, but they don't scale particularly well because they require a human to interpret them.

**Models** are complementary tools to visualization.
Once you have made your questions sufficiently precise, you can use a model to answer them.
Models are fundamentally mathematical or computational tools, so they generally scale well.
Even when they don't, it's usually cheaper to buy more computers than it is to buy more brains!
But every model makes assumptions, and by its very nature, a model cannot question its own assumptions.
That means a model cannot fundamentally surprise you.

::: callout-note
TODO
:::

La derni√®re √©tape de la science des donn√©es est la **communication**, une partie absolument cruciale de tout projet d'analyse de donn√©es.
Peu importe √† quel point vos mod√®les et visualisations vous ont permis de comprendre les donn√©es, cela n'a aucune importance si vous ne pouvez pas aussi communiquer vos r√©sultats aux autres.

Transversalement √† toutes ces √©tapes, il y a la **programmation**.
Vous l'utiliserez dans presque toutes les parties d'un projet de science des donn√©es.
Vous n'avez pas besoin d'√™tre un programmeur expert pour √™tre un data scientist performant, mais c'est une bonne chose d'en apprendre davantage car devenir un meilleur niveau vous permettra d'automatiser des t√¢ches courantes et de r√©soudre plus facilement les probl√®mes que vous rencontrerez.

Vous utiliserez ces outils dans chaque projet de science des donn√©es, mais ils ne suffisent pas pour la plupart.
Il existe une r√®gle approximative des 80/20 : vous pouvez aborder environ 80 % de chaque projet en utilisant les outils que vous apprendrez dans ce livre, mais vous en aurez besoin d'autres pour aborder les 20 % restants.
Tout au long de ce livre, nous vous indiquerons des ressources o√π vous pourrez en apprendre davantage sur ceux-ci.

## Comment ce livre s'organise

La description pr√©c√©dente des outils de la science des donn√©es est organis√©e approximativement selon l'ordre d'utilisation lors d'une analyse.
Cependant, notre exp√©rience nous a montr√© que commencer par l'importation et le nettoyage des donn√©es n'est pas la m√©thode la plus optimale.
En effet, cette √©tape est routini√®re et ennuyeuse dans 80 % des cas, et frustrante et complexe dans les 20 % restants.
Nous pr√©f√©rons donc d√©buter par la visualisation et la transformation de donn√©es d√©j√† import√©es et nettoy√©es.
Ainsi, lorsque vous en arriverez √† importer et nettoyer vos propres donn√©es, votre motivation restera √©lev√©e car vous saurez que cela en vaut la peine.

Dans chaque chapitre, nous suivons un sch√©ma coh√©rent : nous commen√ßons par quelques exemples motivants pour vous donner une vue d'ensemble, puis nous approfondissons les d√©tails.
Chaque section du livre est accompagn√©e d'exercices pour vous aider √† pratiquer ce que vous avez appris.
Bien qu'il puisse √™tre tentant de sauter ces exercices, il n'y a pas de meilleure fa√ßon d'apprendre que de s'exercer sur des probl√®mes r√©els.

## Ce que vous n'apprendrez pas

Il y a plusieurs sujets importants que ce livre ne couvre pas.
Nous pensons qu'il est essentiel de rester concentr√© sur l'essentiel afin que vous puissiez d√©marrer le plus rapidement possible.
Cela signifie que ce livre ne peut pas √™tre exhaustif.

### La mod√©lisation

La mod√©lisation est extr√™mement importante pour la science des donn√©es, mais c'est un sujet vaste, et malheureusement, nous n'avons tout simplement pas l'espace pour lui accorder l'attention qu'il m√©rite ici.
Pour en savoir plus sur la mod√©lisation, nous recommandons vivement [Tidy Modeling with R](https://www.tmwr.org) de nos coll√®gues Max Kuhn et Julia Silge.
Ce livre vous apprendra √† utiliser la famille de packages *tidymodels* qui, comme vous pouvez le deviner d'apr√®s le nom, partagent de nombreuses conventions avec les packages *tidyverse* que nous utilisons dans ce livre.

### Le Big data

Ce livre se focalise sur la gestion de petits ensembles de donn√©es stock√©es en m√©moire, ce qui constitue une excellente base.
En effet, il est essentiel de ma√Ætriser le traitement de volumes de donn√©es plus modestes avant de s'attaquer au big data.
Les m√©thodes pr√©sent√©es ici permettent de g√©rer ais√©ment des centaines de m√©gaoctets de donn√©es et, avec les pr√©cautions n√©cessaires, elles peuvent s'appliquer √† quelques gigaoctets.
Vous apprendrez √©galement √† extraire des informations de formats de fichiers fr√©quemment utilis√©s pour le stockage de grandes quantit√©s de donn√©es.
Bien que vous ne puissiez pas traiter l'int√©gralit√© d'un tel jeu de donn√©es, cela ne pose pas de probl√®me ; il suffit souvent d'un sous-ensemble ou d'un √©chantillon pour r√©pondre √† vos interrogations.

Pour ceux qui manipulent r√©guli√®rement de grands volumes de donn√©es, entre 10 et 100 Go, nous conseillons de se familiariser avec [data.table](https://github.com/Rdatatable/data.table).
Bien que non abord√© dans cet ouvrage car il repose sur une interface diff√©rente de celle du tidyverse et requiert l'adoption de certaines conventions sp√©cifiques, data.table offre une rapidit√© d'ex√©cution remarquable.
Les gains de performance obtenus justifient amplement l'investissement de temps n√©cessaire √† son apprentissage pour ceux qui g√®rent de grandes quantit√©s de donn√©es.

### Python, Julia, et autres langages

Dans cet ouvrage, nous ne traiterons pas de Python, Julia ou d'autres langages de programmation couramment utilis√©s en science des donn√©es.
Cela ne signifie pas que nous consid√©rons ces outils comme inad√©quats‚Äîbien au contraire !
En effet, il est fr√©quent que les √©quipes de science des donn√©es emploient une combinaison de plusieurs langages, souvent incluant √† la fois R et Python.
Toutefois, nous sommes convaincus qu'il est plus efficace d'apprendre et de ma√Ætriser un outil √† la fois.
R est donc propos√© comme point de d√©part id√©al dans cet apprentissage.

## Pr√©requis

Nous partons du principe que vous avez certaines connaissances pr√©alables pour profiter pleinement de ce livre.
Une familiarit√© avec les chiffres est recommand√©e, et une exp√©rience de base en programmation est un atout.
Si vous n'avez jamais programm√©, le livre [Hands on Programming with R](https://rstudio-education.github.io/hopr/) de Garrett peut se r√©v√©ler √™tre un compl√©ment utile √† cette lecture.

Pour mettre en pratique les exemples de code pr√©sent√©s dans ce livre, quatre √©l√©ments sont n√©cessaires : le logiciel R, l'environnement de d√©veloppement RStudio, un ensemble de paquets R connu sous le nom de **tidyverse**, ainsi que quelques autres paquets.
Les paquets constituent les composantes essentielles d'un code R reproductible.
Ils contiennent des fonctions r√©utilisables, une documentation expliquant leur utilisation, et des jeux de donn√©es d'exemples.

### R

Pour t√©l√©charger R, visitez le site de CRAN (**C**omprehensive **R** **A**rchive **N**etwork) √† l'adresse suivante : <https://cloud.r-project.org.>
R est mis √† jour fr√©quemment, avec une version majeure publi√©e annuellement et 2 √† 3 versions mineures chaque ann√©e.
Il est judicieux de mettre √† jour votre installation r√©guli√®rement.
Bien que la mise √† niveau puisse √™tre fastidieuse‚Äîsurtout pour les versions majeures, qui exigent la r√©installation de tous vos paquets‚Äîrepousser ces mises √† jour ne fait qu'aggraver la situation.
Pour travailler avec ce livre, nous recommandons d'utiliser la version 4.2.0 de R ou toute version ult√©rieure.

### RStudio

RStudio is an integrated development environment, or IDE, for R programming, which you can download from <https://posit.co/download/rstudio-desktop/>.
RStudio is updated a couple of times a year, and it will automatically let you know when a new version is out, so there's no need to check back.
It's a good idea to upgrade regularly to take advantage of the latest and greatest features.
For this book, make sure you have at least RStudio 2022.02.0.

When you start RStudio, @fig-rstudio-console, you'll see two key regions in the interface: the console pane and the output pane.
For now, all you need to know is that you type the R code in the console pane and press enter to run it.
You'll learn more as we go along![^intro-1]

[^intro-1]: If you'd like a comprehensive overview of all of RStudio's features, see the RStudio User Guide at <https://docs.posit.co/ide/user>.

```{r}
#| label: fig-rstudio-console
#| echo: false
#| out-width: ~
#| fig-cap: |
#|   The RStudio IDE has two key regions: type R code in the console pane
#|   on the left, and look for plots in the output pane on the right.
#| fig-alt: |
#|   The RStudio IDE with the panes Console and Output highlighted.
knitr::include_graphics("diagrams/rstudio/console.png", dpi = 270)
```

### Le tidyverse

You'll also need to install some R packages.
An R **package** is a collection of functions, data, and documentation that extends the capabilities of base R.
Using packages is key to the successful use of R.
The majority of the packages that you will learn in this book are part of the so-called tidyverse.
All packages in the tidyverse share a common philosophy of data and R programming and are designed to work together.

You can install the complete tidyverse with a single line of code:

```{r}
#| eval: false

install.packages("tidyverse")
```

On your computer, type that line of code in the console, and then press enter to run it.
R will download the packages from CRAN and install them on your computer.

You will not be able to use the functions, objects, or help files in a package until you load it with `library()`.
Once you have installed a package, you can load it using the `library()` function:

```{r}
library(tidyverse)
```

This tells you that tidyverse loads nine packages: dplyr, forcats, ggplot2, lubridate, purrr, readr, stringr, tibble, tidyr.
These are considered the **core** of the tidyverse because you'll use them in almost every analysis.

Packages in the tidyverse change fairly frequently.
You can see if updates are available by running `tidyverse_update()`.

### Autres packages

There are many other excellent packages that are not part of the tidyverse because they solve problems in a different domain or are designed with a different set of underlying principles.
This doesn't make them better or worse; it just makes them different.
In other words, the complement to the tidyverse is not the messyverse but many other universes of interrelated packages.
As you tackle more data science projects with R, you'll learn new packages and new ways of thinking about data.

We'll use many packages from outside the tidyverse in this book.
For example, we'll use the following packages because they provide interesting datasets for us to work with in the process of learning R:

```{r}
#| eval: false

install.packages(
  c("arrow", "babynames", "curl", "duckdb", "gapminder", 
    "ggrepel", "ggridges", "ggthemes", "hexbin", "janitor", "Lahman", 
    "leaflet", "maps", "nycflights13", "openxlsx", "palmerpenguins", 
    "repurrrsive", "tidymodels", "writexl")
  )
```

We'll also use a selection of other packages for one off examples.
You don't need to install them now, just remember that whenever you see an error like this:

```{r}
#| eval: false

library(ggrepel)
#> Error in library(ggrepel) : there is no package called ‚Äòggrepel‚Äô
```

You need to run `install.packages("ggrepel")` to install the package.

## Ex√©cuter un code R

The previous section showed you several examples of running R code.
The code in the book looks like this:

```{r}
#| eval: true
1 + 2
```

If you run the same code in your local console, it will look like this:

```         
> 1 + 2
[1] 3
```

There are two main differences.
In your console, you type after the `>`, called the **prompt**; we don't show the prompt in the book.
In the book, the output is commented out with `#>`; in your console, it appears directly after your code.
These two differences mean that if you're working with an electronic version of the book, you can easily copy code out of the book and paste it into the console.

Throughout the book, we use a consistent set of conventions to refer to code:

-   Functions are displayed in a code font and followed by parentheses, like `sum()` or `mean()`.

-   Other R objects (such as data or function arguments) are in a code font, without parentheses, like `flights` or `x`.

-   Sometimes, to make it clear which package an object comes from, we'll use the package name followed by two colons, like `dplyr::mutate()` or `nycflights13::flights`.
    This is also valid R code.

## Remerciements

This book isn't just the product of Hadley, Mine, and Garrett but is the result of many conversations (in person and online) that we've had with many people in the R community.
We're incredibly grateful for all the conversations we've had with y'all; thank you so much!

```{r}
#| eval: false
#| echo: false

library(tidyverse)
contribs_all_json <- gh::gh("/repos/:owner/:repo/contributors",
  owner = "hadley",
  repo = "r4ds",
  .limit = Inf
)
contribs_all <- tibble(
  login = contribs_all_json |> map_chr("login"),
  n = contribs_all_json |> map_int("contributions")
)

contribs_old <- read_csv("contributors.csv", col_types = list())
contribs_new <- contribs_all |> anti_join(contribs_old, by = "login")

# Get info for new contributors
needed_json <- map(
  contribs_new$login, 
  ~ gh::gh("/users/:username", username = .x),
  .progress = TRUE
)
info_new <- tibble(
  login = contribs_new$login,
  name = map_chr(needed_json, "name", .default = NA),
  blog = map_chr(needed_json, "blog", .default = NA)
)
info_old <- contribs_old |> select(login, name, blog)
info_all <- bind_rows(info_old, info_new)

contribs_all <- contribs_all |> 
  left_join(info_all, by = "login") |> 
  mutate(login_lowercase = str_to_lower(login)) |>
  arrange(login_lowercase) |>
  select(-login_lowercase)
write_csv(contribs_all, "contributors.csv")
```

```{r}
#| results: asis
#| echo: false
#| message: false

library(dplyr)
contributors <- readr::read_csv("contributors.csv")
contributors <- contributors |> 
  filter(!login %in% c("hadley", "garrettgman", "mine-cetinkaya-rundel")) |> 
  mutate(
    login = paste0("\\@", login),
    desc = ifelse(is.na(name), login, paste0(name, " (", login, ")"))
  )

cat("This book was written in the open, and many people contributed via pull requests. A special thanks to all ",nrow(contributors), " of you who contributed improvements via GitHub pull requests (in alphabetical order by username): ", sep = "")
cat(paste0(contributors$desc, collapse = ", "))
cat(".\n")
```

## Colophon

An online version of this book is available at <https://r4ds.hadley.nz>.
It will continue to evolve in between reprints of the physical book.
The source of the book is available at <https://github.com/hadley/r4ds>.
The book is powered by [Quarto](https://quarto.org), which makes it easy to write books that combine text and executable code.

```{r}
#| eval: false
#| echo: false
#| results: asis

pkgs <- sessioninfo::package_info(
  tidyverse:::tidyverse_packages(),
  dependencies = FALSE
)
df <- tibble(
  package = pkgs$package,
  version = pkgs$ondiskversion,
  source = gsub("@", "\\\\@", pkgs$source)
)
knitr::kable(df, format = "markdown")
```

```{r}
#| include: false

cli:::ruler()
```
